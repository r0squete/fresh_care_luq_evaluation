"""
Graph analysis script for LUQ evaluation visualizations.
arosquete - 2026/02/23
"""

# Imports
import argparse
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from config import OUTPUT_PATH


# Functions
def load_luq_csv_results(results_dir):
    """
    Load LUQ results from CSV files generated by run_evaluation.py

    Parameters:
    -----------
    results_dir : str/Path
        Directory containing LUQ CSV results

    Returns:
    --------
    drifters_data : dict
        {drifter_id: {'summary': df, 'timeseries': df, 'metadata': dict}}
    """
    results_path = Path(results_dir)
    csv_files = list(results_path.glob("luq_results_drifter_*.csv"))

    if not csv_files:
        print(f"No LUQ result CSV files found in {results_dir}")
        return {}

    drifters_data = {}

    for csv_file in csv_files:
        # Extract drifter index from filename
        filename = csv_file.name
        try:
            # luq_results_drifter_XXX_filename.csv
            parts = filename.split("_")
            drifter_idx = int(parts[3])
        except (IndexError, ValueError):
            print(f"Could not parse drifter index from {filename}")
            continue

        # Load CSV
        df = pd.read_csv(csv_file)

        if df.empty:
            continue

        # Separate summary and timeseries data
        summary_df = df[df["data_type"] == "summary"].copy()
        timeseries_df = df[df["data_type"] == "timeseries"].copy()

        # Convert datetime strings back to datetime objects for timeseries
        if not timeseries_df.empty:
            timeseries_df["t0_datetime"] = pd.to_datetime(timeseries_df["t0_datetime"])

        # Extract metadata
        if not summary_df.empty:
            metadata = {
                "filename": summary_df["drifter_filename"].iloc[0],
                "L_characteristic_km": summary_df["L_characteristic_km"].iloc[0],
            }
        else:
            metadata = {
                "filename": f"drifter_{drifter_idx}",
                "L_characteristic_km": np.nan,
            }

        drifters_data[drifter_idx] = {
            "summary": summary_df,
            "timeseries": timeseries_df,
            "metadata": metadata,
        }

    print(
        f"Loaded results for {len(drifters_data)} drifters from {len(csv_files)} CSV files"
    )
    return drifters_data


def plot_luq_time_series_from_csv(
    drifters_data,
    drifter_id=None,
    dataset_names=None,
    tau_days=5,
    r_km=10,
    save_path=None,
):
    """
    Create time series plot of LUQ normalized values from CSV data.

    Parameters:
    -----------
    drifters_data : dict
        Data from load_luq_csv_results()
    drifter_id : int, optional
        Specific drifter ID to plot (default: first available)
    dataset_names : list, optional
        List of datasets to plot (default: all available)
    tau_days : int
        Integration time in days
    r_km : int
        Neighborhood radius in km
    save_path : str, optional
        Path to save figure

    Returns:
    --------
    fig, ax : matplotlib figure and axis
    """
    # Select drifter
    if drifter_id is None:
        drifter_id = list(drifters_data.keys())[0]

    if drifter_id not in drifters_data:
        raise ValueError(f"Drifter {drifter_id} not found in data")

    drifter_data = drifters_data[drifter_id]
    timeseries_df = drifter_data["timeseries"]

    # Filter by tau and r_km
    filtered_df = timeseries_df[
        (timeseries_df["tau_days"] == tau_days) & (timeseries_df["r_km"] == r_km)
    ].copy()

    if filtered_df.empty:
        print(f"No data found for drifter {drifter_id}, tau={tau_days}d, r={r_km}km")
        return None, None

    # Get available datasets
    available_datasets = filtered_df["dataset"].unique()
    if dataset_names is None:
        dataset_names = available_datasets
    else:
        # Filter to only available datasets
        dataset_names = [d for d in dataset_names if d in available_datasets]

    if not dataset_names:
        print("No valid datasets found")
        return None, None

    # Create plot
    fig, ax = plt.subplots(figsize=(10, 6))

    # Define colors for different datasets
    colors = {
        "ADT-SST": "purple",
        "ADT-SSS": "blue",
        "ADT-0.05": "olive",
        "ADT-0.25": "orange",
        "OSCAR": "red",
        "OSCAR_geos": "green",
    }

    for dataset_name in dataset_names:
        # Get data for this dataset
        dataset_df = filtered_df[filtered_df["dataset"] == dataset_name].copy()

        if dataset_df.empty:
            print(f"No data for dataset {dataset_name}")
            continue

        # Sort by time
        dataset_df = dataset_df.sort_values("t0_datetime")

        color = colors.get(dataset_name, "black")
        ax.plot(
            dataset_df["t0_datetime"],
            dataset_df["luq_normalized"],
            color=color,
            label=dataset_name,
            linewidth=2.0,
        )

        print(f"  {dataset_name}: {len(dataset_df)} points")

    # Format plot
    ax.set_xlabel("tâ‚€", fontsize=14)
    ax.set_ylabel("LUQ normalized mean", fontsize=14)
    ax.legend(fontsize=12, loc="upper right")
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 1)

    # Format x-axis to show dates
    ax.tick_params(axis="x", rotation=45, labelsize=11)
    ax.tick_params(axis="y", labelsize=11)

    plt.tight_layout()

    if save_path:
        fig.savefig(save_path, dpi=300, bbox_inches="tight")
        print(f"Plot saved: {save_path}")

    return fig, ax


def main():
    """Main function for command-line usage"""
    parser = argparse.ArgumentParser(
        description="Generate LUQ analysis plots from CSV results",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--results_dir",
        type=str,
        default=OUTPUT_PATH,
        help="Directory with LUQ CSV results",
    )

    parser.add_argument(
        "--drifter_id",
        type=int,
        default=None,
        help="Specific drifter ID to plot (default: first available)",
    )

    parser.add_argument(
        "--datasets",
        nargs="+",
        default=None,
        help="Datasets to plot (default: all available)",
    )

    parser.add_argument(
        "--tau_days",
        type=int,
        default=5,
        help="Integration time in days for time series plot",
    )

    parser.add_argument(
        "--r_km", type=int, default=10, help="Neighborhood radius in km"
    )

    parser.add_argument(
        "--save_plots", action="store_true", help="Save plots instead of showing them"
    )

    parser.add_argument(
        "--output_dir",
        type=str,
        default="../results/plots/",
        help="Directory to save plots",
    )

    args = parser.parse_args()

    print("=== LUQ Graph Analysis ===")
    print(f"Loading data from: {args.results_dir}")

    # Load CSV data
    drifters_data = load_luq_csv_results(args.results_dir)

    if not drifters_data:
        print("No data loaded. Exiting.")
        return

    # Create output directory if saving
    if args.save_plots:
        output_path = Path(args.output_dir)
        output_path.mkdir(exist_ok=True)

    # Time series plot only
    print("\nCreating time series plot...")
    fig, ax = plot_luq_time_series_from_csv(
        drifters_data,
        drifter_id=args.drifter_id,
        dataset_names=args.datasets,
        tau_days=args.tau_days,
        r_km=args.r_km,
        save_path=f"{args.output_dir}/timeseries_drifter_{args.drifter_id or 'auto'}_tau{args.tau_days}_r{args.r_km}.png"
        if args.save_plots
        else None,
    )

    if fig and not args.save_plots:
        plt.show()
    elif fig:
        plt.close(fig)

    print("\nAnalysis completed!")


if __name__ == "__main__":
    main()
